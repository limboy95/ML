{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape written: (45000, 784)\n",
      "shape spoken (45000,)\n",
      "shape spoken indiv: (38, 13)\n",
      "13\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "written_train =numpy.load(\"written_train(1).npy\")\n",
    "spoken_train =numpy.load(\"spoken_train(1).npy\")\n",
    "match_train = numpy.load(\"match_train(1).npy\")\n",
    "feature_amount = spoken_train[0].shape[1]\n",
    "print(\"shape written:\", written_train.shape)\n",
    "print(\"shape spoken\", spoken_train.shape)\n",
    "print(\"shape spoken indiv:\", spoken_train[4].shape)\n",
    "print(feature_amount)\n",
    "print(match_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 93, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., -1,  0,  0],\n",
       "       [ 0,  0,  0, ..., -2,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ..., -1,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "\n",
    "maxs = []\n",
    "for i in range(0, len(spoken_train)):\n",
    "    maxs.append(spoken_train[i].shape[0])\n",
    "maxlen_spoken_train = max(maxs)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "spoken_test_3d= pad_sequences(spoken_train, maxlen= max(maxs))\n",
    "print(spoken_train_3d.shape)\n",
    "\n",
    "spoken_train_2d =spoken_train_3d.reshape(45000, maxlen_spoken_train*feature_amount)\n",
    "\n",
    "spoken_train_2d\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user2\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\user2\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm_scaler = MinMaxScaler()\n",
    "spoken_train_mmsc = mm_scaler.fit_transform(spoken_train_2d)\n",
    "written_train_mmsc = mm_scaler.fit_transform(written_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 1993)\n"
     ]
    }
   ],
   "source": [
    "X_train = numpy.hstack([spoken_train_mmsc, written_train_mmsc])\n",
    "print(X_train.shape)\n",
    "y_train=match_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 40461\n",
      "Before OverSampling, counts of label '2': 4539 \n",
      "[[0.         0.         0.         ... 1.         1.         1.        ]\n",
      " [0.         0.         0.         ... 0.875      0.875      0.625     ]\n",
      " [0.         0.         0.         ... 1.         1.         1.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.97146594 0.88451135]\n",
      " [0.         0.         0.         ... 0.81456298 0.96771851 1.        ]\n",
      " [0.         0.         0.         ... 0.87116476 1.         0.80674715]]\n",
      "After OverSampling, the shape of X: (80922, 1993)\n",
      "After OverSampling, the shape of y: (80922,) \n",
      "\n",
      "After OverSampling, counts of label '1': 40461\n",
      "After OverSampling, counts of label '2': 40461\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==0)))\n",
    "print(\"Before OverSampling, counts of label '2': {} \".format(sum(y_train==1)))\n",
    "\n",
    "sm = SMOTE(random_state=4)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of X: {}'.format(X_res.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(y_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==0)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_res==1)))\n",
    "\n",
    "\n",
    "X= numpy.array(X_res)\n",
    "y= numpy.array(y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80922,)\n"
     ]
    }
   ],
   "source": [
    "X_train=X\n",
    "y_train=y\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user2\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y)\n",
    "print(y_train)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = y_train.reshape(len(y_train), 1)\n",
    "y_train = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80922, 1993)\n"
     ]
    }
   ],
   "source": [
    " print(X_train.shape)\n",
    "X_train = X_train.reshape(80922,1,1993)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80922, 1, 1993)\n",
      "(80922, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54217 samples, validate on 26705 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5882 - acc: 0.2587 - val_loss: 1.3790 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.5664 - acc: 0.2537 - val_loss: 1.3774 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.5664 - acc: 0.2537 - val_loss: 1.3804 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.5665 - acc: 0.2537 - val_loss: 1.3756 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.5664 - acc: 0.2537 - val_loss: 1.3491 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.5665 - acc: 0.2537 - val_loss: 1.3783 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.5665 - acc: 0.2537 - val_loss: 1.4089 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.5665 - acc: 0.2537 - val_loss: 1.3768 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.5664 - acc: 0.2537 - val_loss: 1.3773 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.5664 - acc: 0.2537 - val_loss: 1.3949 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266d68c0be0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "#### LSTM MODEL\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=False, input_shape=(1,1993)))\n",
    "#model.add(Dense(32, input_dim=784))\n",
    "model.add(Dense((2)))\n",
    "\n",
    "#### EARLY STOPPING AND CALLBACK\n",
    "#callbacks_list = [\n",
    "#    keras.callbacks.ModelCheckpoint(\n",
    " #       filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "#        monitor='val_loss', save_best_only=True),\n",
    " #       keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n",
    "\n",
    "#keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=500, verbose=2,\n",
    "        validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "written_test =numpy.load(\"written_test(1).npy\")\n",
    "spoken_test =numpy.load(\"spoken_test(1).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 93, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., -1,  0,  1],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ..., -2,  0,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., -2, -1,  0],\n",
       "       [ 0,  0,  0, ..., -2, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "\n",
    "maxs = []\n",
    "for i in range(0, len(spoken_test)):\n",
    "    maxs.append(spoken_test[i].shape[0])\n",
    "maxlen_spoken_test = max(maxs)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "spoken_test_3d= pad_sequences(spoken_test, maxlen= max(maxs))\n",
    "print(spoken_test_3d.shape)\n",
    "\n",
    "spoken_test_2d =spoken_test_3d.reshape(15000, maxlen_spoken_test*feature_amount)\n",
    "\n",
    "spoken_test_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user2\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\user2\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "spoken_test_mmsc = mm_scaler.fit_transform(spoken_test_2d)\n",
    "written_test_mmsc = mm_scaler.fit_transform(written_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = numpy.hstack([spoken_test_mmsc, written_test_mmsc])\n",
    "X_test = X_test.reshape(15000,1,1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 42us/step\n",
      "[0 0 0 ... 0 0 0]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict_classes(X_test, verbose=1)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "print(1 in match_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([40461,  4539], dtype=int64))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.unique(match_train, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
